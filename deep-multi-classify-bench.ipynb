{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJsVDmvgeXpu"
   },
   "source": [
    "# Deep Learning Project - Thomas Testbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjO0DSS4eXpz",
    "outputId": "3b4fbfd3-c33b-46bb-a27a-7061c9c5f22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: procgen in /home/worstwizard/.local/lib/python3.8/site-packages (0.10.4)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from procgen) (3.0.12)\n",
      "Requirement already satisfied: gym<1.0.0,>=0.15.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from procgen) (0.17.3)\n",
      "Requirement already satisfied: gym3<1.0.0,>=0.3.3 in /home/worstwizard/.local/lib/python3.8/site-packages (from procgen) (0.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in /usr/lib/python3.8/site-packages (from procgen) (1.19.1)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3.8/site-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.2)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym<1.0.0,>=0.15.0->procgen) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym<1.0.0,>=0.15.0->procgen) (1.6.0)\n",
      "Requirement already satisfied: imageio-ffmpeg<0.4.0,>=0.3.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym3<1.0.0,>=0.3.3->procgen) (0.3.0)\n",
      "Requirement already satisfied: imageio<3.0.0,>=2.6.0 in /usr/lib/python3.8/site-packages (from gym3<1.0.0,>=0.3.3->procgen) (2.8.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.13.0 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.14.3)\n",
      "Requirement already satisfied: glfw<2.0.0,>=1.8.6 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym3<1.0.0,>=0.3.3->procgen) (1.12.0)\n",
      "Requirement already satisfied: moderngl<6.0.0,>=5.5.4 in /home/worstwizard/.local/lib/python3.8/site-packages (from gym3<1.0.0,>=0.3.3->procgen) (5.6.2)\n",
      "Requirement already satisfied: future in /usr/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym<1.0.0,>=0.15.0->procgen) (0.18.2)\n",
      "Requirement already satisfied: pillow in /usr/lib/python3.8/site-packages (from imageio<3.0.0,>=2.6.0->gym3<1.0.0,>=0.3.3->procgen) (7.2.0)\n",
      "Requirement already satisfied: pycparser in /home/worstwizard/.local/lib/python3.8/site-packages (from cffi<2.0.0,>=1.13.0->gym3<1.0.0,>=0.3.3->procgen) (2.20)\n",
      "Requirement already satisfied: glcontext<3,>=2 in /home/worstwizard/.local/lib/python3.8/site-packages (from moderngl<6.0.0,>=5.5.4->gym3<1.0.0,>=0.3.3->procgen) (2.2.0)\n",
      "--2020-12-09 00:49:14--  https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/utils.py\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.128.133, 151.101.0.133, 151.101.192.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.128.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17786 (17K) [text/plain]\n",
      "Saving to: ‘utils.py.1’\n",
      "\n",
      "utils.py.1          100%[===================>]  17,37K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-09 00:49:14 (44,4 MB/s) - ‘utils.py.1’ saved [17786/17786]\n",
      "\n",
      "--2020-12-09 00:49:14--  https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/classifier.py\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.128.133, 151.101.192.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.128.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1635 (1,6K) [text/plain]\n",
      "Saving to: ‘classifier.py.1’\n",
      "\n",
      "classifier.py.1     100%[===================>]   1,60K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-09 00:49:14 (52,9 MB/s) - ‘classifier.py.1’ saved [1635/1635]\n",
      "\n",
      "--2020-12-09 00:49:15--  https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/TrainedClassifier.pt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13335031 (13M) [application/octet-stream]\n",
      "Saving to: ‘TrainedClassifier.pt.1’\n",
      "\n",
      "TrainedClassifier.p 100%[===================>]  12,72M  29,2MB/s    in 0,4s    \n",
      "\n",
      "2020-12-09 00:49:15 (29,2 MB/s) - ‘TrainedClassifier.pt.1’ saved [13335031/13335031]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "#!pip install procgen\n",
    "#!wget https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/utils.py\n",
    "#!wget https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/classifier.py\n",
    "#!wget https://raw.githubusercontent.com/ThomasConrad/ProcgenDeepLearning/main/TrainedClassifier.pt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import make_env, Storage, orthogonal_init\n",
    "from classifier import Net\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP9qpqXqeXpz"
   },
   "source": [
    "### Hyperparameters\n",
    "Leave unchanged between comparison runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ha-WaQDFeXp0"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "total_steps = 8e6\n",
    "num_envs = 48\n",
    "num_levels = 10\n",
    "num_steps = 256\n",
    "num_epochs = 3\n",
    "batch_size = 256\n",
    "eps = .2\n",
    "grad_eps = .5\n",
    "value_coef = .5\n",
    "entropy_coef = .01\n",
    "feature_dim = 256\n",
    "\n",
    "env_name = 'starpilot,coinrun,bigfish'\n",
    "use_mixreg = False\n",
    "gamma = 0.999\n",
    "increase = 1 # How much to augment the dataset with mixreg\n",
    "alpha = 0.5 # Alpha value to use for the beta-distribution in mixreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLzhGitJeXp0"
   },
   "source": [
    "### Network Definition\n",
    "Leave unchanged between comparison runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0KUl3vsteXp0"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier_model = Net(3,64,64,16) #Get this right, check the trained model params\n",
    "        self.classifier_model.load_state_dict(torch.load(\"TrainedClassifier.pt\"))\n",
    "        self.classifier_model.eval()\n",
    "        #self.classifier_model\n",
    "    def forward(self,x):\n",
    "        with torch.no_grad():\n",
    "            x = self.classifier_model(x)\n",
    "            return x\n",
    "\n",
    "class NatureModel(nn.Module):\n",
    "  def __init__(self, in_channels, feature_dim):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4), nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_features=64),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1), nn.ReLU(),\n",
    "        Flatten(),\n",
    "        nn.Linear(in_features=1024, out_features=feature_dim), nn.ReLU()\n",
    "    )\n",
    "    self.apply(orthogonal_init)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(x)\n",
    "        out = self.conv1(out)\n",
    "        out = nn.ReLU()(out)\n",
    "        out = self.conv2(out)\n",
    "        return out + x\n",
    "\n",
    "class ImpalaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ImpalaBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.res1 = ResidualBlock(out_channels)\n",
    "        self.res2 = ResidualBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        return x\n",
    "\n",
    "def xavier_uniform_init(module, gain=1.0):\n",
    "    if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(module.weight.data, gain)\n",
    "        nn.init.constant_(module.bias.data, 0)\n",
    "    return module\n",
    "\n",
    "class ImpalaModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels, \n",
    "                 feature_dim,\n",
    "                 **kwargs):\n",
    "        super(ImpalaModel, self).__init__()\n",
    "        self.block1 = ImpalaBlock(in_channels=in_channels, out_channels=16)\n",
    "        self.block2 = ImpalaBlock(in_channels=16, out_channels=32)\n",
    "        self.block3 = ImpalaBlock(in_channels=32, out_channels=32)\n",
    "        self.fc = nn.Linear(in_features=32 * 8 * 8 + 16, out_features=feature_dim)\n",
    "\n",
    "        self.output_dim = 256\n",
    "        self.apply(xavier_uniform_init)\n",
    "\n",
    "        self.classifier = ClassifierModule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.block1(x)\n",
    "        y = self.block2(y)\n",
    "        y = self.block3(y)\n",
    "        y = nn.ReLU()(y)\n",
    "        y = Flatten()(y)\n",
    "        z = torch.cat([y, self.classifier(x)], dim=1)\n",
    "        z = self.fc(z)\n",
    "        z = nn.ReLU()(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  def __init__(self, encoder, feature_dim, num_actions):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.policy = orthogonal_init(nn.Linear(feature_dim, num_actions), gain=.01)\n",
    "    self.value = orthogonal_init(nn.Linear(feature_dim, 1), gain=1.)\n",
    "\n",
    "  def act(self, x):\n",
    "    with torch.no_grad():\n",
    "      x = x.cuda().contiguous()\n",
    "      dist, value = self.forward(x)\n",
    "      action = dist.sample()\n",
    "      log_prob = dist.log_prob(action)\n",
    "    \n",
    "    return action.cpu(), log_prob.cpu(), value.cpu()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    logits = self.policy(x)\n",
    "    value = self.value(x).squeeze(1)\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "\n",
    "    return dist, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DMSLKx7eXp1"
   },
   "source": [
    "## Environment and training definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "-n9Otm1HeXp1",
    "outputId": "69c0e01d-17fc-4025-c4d1-3801e6b84d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
      "Action space: 15\n",
      "Nr. of environments: 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-22a7af8e25d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Define network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImpalaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c8e1984e34e5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, feature_dim, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxavier_uniform_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c8e1984e34e5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Get this right, check the trained model params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TrainedClassifier.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#self.classifier_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Change this for comparison purposes\n",
    "use_mixreg  = False\n",
    "\n",
    "# Define environment\n",
    "# check the utils.py file for info on arguments\n",
    "env = make_env(num_envs, num_levels=num_levels,env_name=env_name)\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Action space:', env.action_space.n)\n",
    "\n",
    "eval_environments = {}\n",
    "# Define validation environments\n",
    "env_names = env_name.split(',')\n",
    "for e in env_names:\n",
    "    eval_environments[e] = make_env(num_envs, start_level=num_levels, num_levels=num_levels,env_name=e)\n",
    "print(\"Nr. of environments:\", len(eval_environments))\n",
    "\n",
    "# Define network\n",
    "encoder = ImpalaModel(3,256)\n",
    "policy = Policy(encoder, 256, env.action_space.n)\n",
    "policy.cuda()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=5e-4, eps=1e-5, weight_decay = 1e-5)\n",
    "\n",
    "# Define temporary storage\n",
    "# we use this to collect transitions during each iteration\n",
    "storage = Storage(\n",
    "    env.observation_space.shape,\n",
    "    num_steps,\n",
    "    num_envs,\n",
    "    gamma=gamma\n",
    ")\n",
    "\n",
    "## Filename for checkpoints\n",
    "checkpoint_file_name = 'checkpoint'\n",
    "if use_mixreg:\n",
    "    checkpoint_file_name += '_mixreg'\n",
    "else:\n",
    "    checkpoint_file_name += '_basic'\n",
    "checkpoint_file_name += '.pt'\n",
    "\n",
    "data_log_file_name = 'training_stats'\n",
    "if use_mixreg:\n",
    "    data_log_file_name += '_mixreg'\n",
    "else:\n",
    "    data_log_file_name += '_basic'\n",
    "data_log_file_name += '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKudBVljeXp2"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvjkJYfzeXp2"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "obs = env.reset()\n",
    "v_obs = eval_environments[list(eval_environments)[0]].reset()\n",
    "step = 0\n",
    "\n",
    "data_log = []\n",
    "while step < total_steps:\n",
    "\n",
    "  # Use policy to collect data for num_steps steps\n",
    "  policy.eval()\n",
    "  for _ in range(num_steps):\n",
    "    # Use policy\n",
    "    action, log_prob, value = policy.act(obs)\n",
    "    \n",
    "    # Take step in environment\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "    # Store data\n",
    "    storage.store(obs, action, reward, done, info, log_prob, value)\n",
    "    \n",
    "    # Update current observation\n",
    "    obs = next_obs\n",
    "\n",
    "  # Add the last observation to collected data\n",
    "  _, _, value = policy.act(obs)\n",
    "  storage.store_last(obs, value)\n",
    "\n",
    "  # Compute return and advantage\n",
    "  storage.compute_return_advantage()\n",
    "\n",
    "  # Optimize policy\n",
    "  policy.train()\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    # Iterate over batches of transitions\n",
    "    if use_mixreg:\n",
    "        generator = storage.get_mix_generator(increase, alpha, batch_size)\n",
    "    else:\n",
    "        generator = storage.get_generator(batch_size)\n",
    "        \n",
    "    for batch in generator:\n",
    "      b_obs, b_action, b_log_prob, b_value, b_returns, b_advantage = batch\n",
    "\n",
    "      # Get current policy outputs\n",
    "      new_dist, new_value = policy(b_obs)\n",
    "      new_log_prob = new_dist.log_prob(b_action)\n",
    "\n",
    "      # Clipped policy objective\n",
    "      ratio = torch.exp(new_log_prob - b_log_prob)\n",
    "      clipped_ratio = ratio.clamp(min=1.0 - eps,max=1.0 + eps)\n",
    "      policy_reward = torch.min(ratio * b_advantage, clipped_ratio * b_advantage)\n",
    "      pi_loss = -policy_reward.mean()\n",
    "\n",
    "      # Clipped value function objective\n",
    "      V_clip = b_value + (new_value-b_value).clamp(-eps,eps)\n",
    "      vf_loss = torch.max((b_value - b_returns) ** 2, (V_clip - b_returns) ** 2)\n",
    "      value_loss = 0.5*vf_loss.mean()\n",
    "\n",
    "      # Entropy loss\n",
    "      entropy_loss = new_dist.entropy().mean()\n",
    "\n",
    "      # Backpropagate losses\n",
    "      loss = pi_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "      loss.backward()\n",
    "\n",
    "      # Clip gradients\n",
    "      torch.nn.utils.clip_grad_norm_(policy.parameters(), grad_eps)\n",
    "\n",
    "      # Update policy\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "  ## VALIDATION ##\n",
    "  # Evaluate policy\n",
    "  policy.eval()\n",
    "  validation_rewards = []\n",
    "  for e in eval_environments:\n",
    "      total_reward = []\n",
    "      for _ in range(num_steps):\n",
    "        # Use policy\n",
    "        v_action, v_log_prob, v_value = policy.act(v_obs)\n",
    "\n",
    "        # Take step in environment\n",
    "        v_obs, v_reward, v_done, v_info = eval_environments[e].step(v_action)\n",
    "        total_reward.append(torch.Tensor(v_reward))\n",
    "\n",
    "      # Calculate average return\n",
    "      total_reward = torch.stack(total_reward).sum(0).mean(0)\n",
    "      validation_rewards.append(total_reward.item())\n",
    "  ## END OF VALIDATION ##\n",
    "      \n",
    "\n",
    "  # Update stats\n",
    "  step += num_envs * num_steps\n",
    "  print(f'Step: {step}\\tMean reward: {storage.get_reward()}\\tMean validation rewards: {validation_rewards}')\n",
    "  data_point = [step, storage.get_reward().item()]\n",
    "  for r in validation_rewards:\n",
    "    data_point.append(r)\n",
    "  data_log.append(data_point)\n",
    "    \n",
    "with open(data_log_file_name, 'w', newline='') as f:\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerows(data_log)\n",
    "\n",
    "print('Completed training!')\n",
    "torch.save(policy.state_dict, checkpoint_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj1ZfgZGeXp3"
   },
   "source": [
    "### Vizualize training results\n",
    "\n",
    "Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm-EM8NweXp3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "csv_files = [\n",
    "  \"training_stats_basic.csv\",\n",
    "  \"training_stats_mixreg.csv\"\n",
    "  ]\n",
    "\n",
    "full_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "  data = {}\n",
    "  data['x'] = []\n",
    "  data['y_train'] = []\n",
    "  data['y_val'] = []\n",
    "\n",
    "  with open(file, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "      data['x'].append(int(row[0]))\n",
    "      data['y_train'].append(float(row[1]))\n",
    "      data['y_val'].append(float(row[2]))\n",
    "\n",
    "  full_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0avEjGpeXp3"
   },
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZMIMJUXeXp4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "for data in full_data:\n",
    "  plt.plot(data['x'], data['y_train'])\n",
    "  plt.plot(data['x'], data['y_val'])\n",
    "\n",
    "plt.legend([\"Basic - Train\",\"Basic - Validation\",\"w/ Mixreg - Train\",\"w/ Mixreg - Validation\"])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgMYrUwteXp4"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# Make evaluation environment\n",
    "eval_env = make_env(num_envs, start_level=num_levels, num_levels=num_levels,env_name='starpilot')\n",
    "obs = eval_env.reset()\n",
    "\n",
    "frames = []\n",
    "total_reward = []\n",
    "\n",
    "# Evaluate policy\n",
    "policy.eval()\n",
    "for _ in range(512):\n",
    "\n",
    "  # Use policy\n",
    "  action, log_prob, value = policy.act(obs)\n",
    "\n",
    "  # Take step in environment\n",
    "  obs, reward, done, info = eval_env.step(action)\n",
    "  total_reward.append(torch.Tensor(reward))\n",
    "\n",
    "  # Render environment and store\n",
    "  frame = (torch.Tensor(eval_env.render(mode='rgb_array'))*255.).byte()\n",
    "  frames.append(frame)\n",
    "\n",
    "# Calculate average return\n",
    "total_reward = torch.stack(total_reward).sum(0).mean(0)\n",
    "print('Average return:', total_reward)\n",
    "\n",
    "# Save frames as video\n",
    "frames = torch.stack(frames)\n",
    "imageio.mimsave('vid.mp4', frames, fps=25)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "deep-multi-bench.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
