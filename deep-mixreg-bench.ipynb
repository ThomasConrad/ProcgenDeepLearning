{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project - KK Testbench\n",
    "\n",
    "Currently testing difference between with/without mixreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import make_env, Storage, orthogonal_init\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Leave unchanged between comparison runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "total_steps = 1e6\n",
    "num_envs = 32\n",
    "num_levels = 10\n",
    "num_steps = 256\n",
    "num_epochs = 3\n",
    "batch_size = 256\n",
    "eps = .2\n",
    "grad_eps = .5\n",
    "value_coef = .75\n",
    "entropy_coef = .1\n",
    "\n",
    "increase = 3 # How much to augment the dataset with mixreg\n",
    "alpha = 0.5 # Alpha value to use for the beta-distribution in mixreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Definition\n",
    "Leave unchanged between comparison runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network definition\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "  def __init__(self, in_channels):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x) + x\n",
    "\n",
    "class SimpleImpalaEncoder(nn.Module):\n",
    "  def __init__(self, in_channels, feature_dim):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1, padding=1),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        ResidualBlock(in_channels),\n",
    "        ResidualBlock(in_channels),\n",
    "        nn.ReLU(),\n",
    "        Flatten(),\n",
    "        nn.Linear(in_features=3072, out_features=feature_dim),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, feature_dim):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=8, stride=4), nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_features=32),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2), nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_features=64),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
    "        nn.BatchNorm2d(num_features=128),\n",
    "        nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1), nn.ReLU(),\n",
    "        Flatten(),\n",
    "        nn.Linear(in_features=1024, out_features=feature_dim), nn.ReLU()\n",
    "    )\n",
    "    self.apply(orthogonal_init)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  def __init__(self, encoder, feature_dim, num_actions):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.policy = orthogonal_init(nn.Linear(feature_dim, num_actions), gain=.01)\n",
    "    self.value = orthogonal_init(nn.Linear(feature_dim, 1), gain=1.)\n",
    "\n",
    "  def act(self, x):\n",
    "    with torch.no_grad():\n",
    "      x = x.cuda().contiguous()\n",
    "      dist, value = self.forward(x)\n",
    "      action = dist.sample()\n",
    "      log_prob = dist.log_prob(action)\n",
    "    \n",
    "    return action.cpu(), log_prob.cpu(), value.cpu()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    logits = self.policy(x)\n",
    "    value = self.value(x).squeeze(1)\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "\n",
    "    return dist, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and training definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(0.0, 1.0, (3, 64, 64), float32)\n",
      "Action space: 15\n"
     ]
    }
   ],
   "source": [
    "# Change this for comparison purposes\n",
    "use_mixreg  = False\n",
    "\n",
    "# Define environment\n",
    "# check the utils.py file for info on arguments\n",
    "env = make_env(num_envs, num_levels=num_levels)\n",
    "print('Observation space:', env.observation_space)\n",
    "print('Action space:', env.action_space.n)\n",
    "\n",
    "# Define network\n",
    "encoder = SimpleImpalaEncoder(3,256)\n",
    "policy = Policy(encoder, 256, env.action_space.n)\n",
    "policy.cuda()\n",
    "\n",
    "# Define optimizer\n",
    "# these are reasonable values but probably not optimal\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=3e-4, eps=1e-5,weight_decay = 0.01)\n",
    "\n",
    "# Define temporary storage\n",
    "# we use this to collect transitions during each iteration\n",
    "storage = Storage(\n",
    "    env.observation_space.shape,\n",
    "    num_steps,\n",
    "    num_envs\n",
    ")\n",
    "\n",
    "## Filename for checkpoints\n",
    "checkpoint_file_name = 'checkpoint'\n",
    "if use_mixreg:\n",
    "    checkpoint_file_name += '_mixreg'\n",
    "else:\n",
    "    checkpoint_file_name += '_basic'\n",
    "checkpoint_file_name += '.pt'\n",
    "\n",
    "data_log_file_name = 'training_stats'\n",
    "if use_mixreg:\n",
    "    checkpoint_file_name += '_mixreg'\n",
    "else:\n",
    "    checkpoint_file_name += '_basic'\n",
    "checkpoint_file_name += '.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training!\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "obs = env.reset()\n",
    "step = 0\n",
    "\n",
    "data_log = []\n",
    "while step < total_steps:\n",
    "\n",
    "  # Use policy to collect data for num_steps steps\n",
    "  policy.eval()\n",
    "  for _ in range(num_steps):\n",
    "    # Use policy\n",
    "    action, log_prob, value = policy.act(obs)\n",
    "    \n",
    "    # Take step in environment\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "\n",
    "    # Store data\n",
    "    storage.store(obs, action, reward, done, info, log_prob, value)\n",
    "    \n",
    "    # Update current observation\n",
    "    obs = next_obs\n",
    "\n",
    "  # Add the last observation to collected data\n",
    "  _, _, value = policy.act(obs)\n",
    "  storage.store_last(obs, value)\n",
    "\n",
    "  # Compute return and advantage\n",
    "  storage.compute_return_advantage()\n",
    "\n",
    "  # Optimize policy\n",
    "  policy.train()\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    # Iterate over batches of transitions\n",
    "    if use_mixreg:\n",
    "        generator = storage.get_mix_generator(increase, alpha, batch_size)\n",
    "    else:\n",
    "        generator = storage.get_generator(batch_size)\n",
    "        \n",
    "    for batch in generator:\n",
    "      b_obs, b_action, b_log_prob, b_value, b_returns, b_advantage = batch\n",
    "\n",
    "      # Get current policy outputs\n",
    "      new_dist, new_value = policy(b_obs)\n",
    "      new_log_prob = new_dist.log_prob(b_action)\n",
    "\n",
    "      # Clipped policy objective\n",
    "      ratio = torch.exp(new_log_prob - b_log_prob)\n",
    "      clipped_ratio = ratio.clamp(min=1.0 - eps,max=1.0 + eps)\n",
    "      policy_reward = torch.min(ratio * b_advantage, clipped_ratio * b_advantage)\n",
    "      pi_loss = -policy_reward.mean()\n",
    "\n",
    "      # Clipped value function objective\n",
    "      V_clip = (new_value-b_value).clamp(-eps,eps)\n",
    "      vf_loss = torch.max((b_value - b_returns) ** 2, (V_clip - b_returns) ** 2)\n",
    "      value_loss = 0.5*vf_loss.mean()\n",
    "\n",
    "      # Entropy loss\n",
    "      entropy_loss = new_dist.entropy().mean()\n",
    "\n",
    "      # Backpropagate losses\n",
    "      loss = pi_loss + value_coef * value_loss - entropy_coef * entropy_loss\n",
    "      loss.backward()\n",
    "\n",
    "      # Clip gradients\n",
    "      torch.nn.utils.clip_grad_norm_(policy.parameters(), grad_eps)\n",
    "\n",
    "      # Update policy\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "  # Update stats\n",
    "  step += num_envs * num_steps\n",
    "  print(f'Step: {step}\\tMean reward: {storage.get_reward()}')\n",
    "  data_point = [step, storage.get_reward().item()]\n",
    "  data_log.append(data_point)\n",
    "    \n",
    "with open(data_log_file_name, 'w', newline='') as f:\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerows(data_log)\n",
    "\n",
    "print('Completed training!')\n",
    "torch.save(policy.state_dict, checkpoint_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
